{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the packages\n",
    "import cv2\n",
    "import os\n",
    "import re\n",
    "import numpy\n",
    "import dlib\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoTransformer():\n",
    "\n",
    "    def __init__(self, fps=30):\n",
    "        self.fps = fps\n",
    "\n",
    "    def video_to_frame(self, path_video, dir_frames):\n",
    "\n",
    "        vidcap = cv2.VideoCapture(path_video)\n",
    "        success,image = vidcap.read()\n",
    "        count = 0\n",
    "        while success:\n",
    "            cv2.imwrite(dir_frames + \"/frame_\" + str(count).zfill(10) + \".jpg\", image)     # save frame as JPEG file      \n",
    "            success,image = vidcap.read()\n",
    "            #print('Read a new frame: ', success)\n",
    "            count += 1\n",
    "\n",
    "\n",
    "    def frame_to_video(self, dir_frames, path_video, fps):\n",
    "        num_img = []\n",
    "        images = []\n",
    "        for img in os.listdir(dir_frames):\n",
    "            if img.endswith(\".png\") or img.endswith(\".jpg\"):\n",
    "                # using List comprehension + isdigit() +split() \n",
    "                # getting numbers from string  \n",
    "                data = img.split(\"_\")\n",
    "                data = data[1].split(\".\")\n",
    "                num = data[0]\n",
    "                #print(num)\n",
    "                num_img.append(num)\n",
    "                images.append(img)\n",
    "\n",
    "        sorted_numbers = numpy.argsort(num_img)\n",
    "        images_sorted = []\n",
    "        #print(images)\n",
    "        for i in range(len(images)):\n",
    "            images_sorted.append(images[sorted_numbers[i]])\n",
    "\n",
    "        frame = cv2.imread(os.path.join(dir_frames, images_sorted[0]))\n",
    "        height, width, layers = frame.shape\n",
    "        fourrc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "        video = cv2.VideoWriter(path_video, fourrc, fps, (width, height))\n",
    "\n",
    "        for image in images_sorted:\n",
    "            frame = cv2.imread(os.path.join(dir_frames, image))\n",
    "            video.write(frame)\n",
    "\n",
    "        cv2.destroyAllWindows()\n",
    "        video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running\n",
      "Folder /home/john/dlib_files/frames already exists\n",
      "Folder /home/john/dlib_files/labeled_frames/ already exists\n",
      "Turn video into frames\n"
     ]
    }
   ],
   "source": [
    "# Set parameters\n",
    "\n",
    "PATH_VID = \"/home/john/dlib_files/input/sample1.mp4\"# location video \n",
    "DIR_FRAMES = \"/home/john/dlib_files/frames\"# directory to store frames (will be created)\n",
    "PATH_VID_AN = \"/home/john/dlib_files/output/sample1_output_0.35_68.mp4\"# name of annotated video\n",
    "DIR_FRAMES_AN = \"/home/john/dlib_files/labeled_frames/\"# directory to store annotated frames (will be created)\n",
    "VID_FPS = 30\n",
    "\n",
    "print(\"running\")\n",
    "\n",
    "# Create objects\n",
    "# img_annotator = ImageAnnotator(PATH_CRED)\n",
    "video_transf = VideoTransformer(VID_FPS)\n",
    "\n",
    "# create folder for frames\n",
    "try:\n",
    "    os.mkdir(DIR_FRAMES)\n",
    "except:\n",
    "    print(\"Folder \" + DIR_FRAMES + \" already exists\")\n",
    "    for filename in os.listdir(DIR_FRAMES):\n",
    "        file_path = os.path.join(DIR_FRAMES, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
    "\n",
    "try:\n",
    "    os.mkdir(DIR_FRAMES_AN)\n",
    "except:\n",
    "    print(\"Folder \" + DIR_FRAMES_AN + \" already exists\")\n",
    "    for filename in os.listdir(DIR_FRAMES_AN):\n",
    "        file_path = os.path.join(DIR_FRAMES_AN, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
    "\n",
    "# Turn video into frames\n",
    "print(\"Turn video into frames\")\n",
    "video_transf.video_to_frame(PATH_VID, DIR_FRAMES)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.expanduser('/home/john/dlib_files')\n",
    "faces_folder_path = data_dir + '/unique_faces/'\n",
    "\n",
    "# Globals\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "shape_predictor = dlib.shape_predictor(data_dir + '/shape_predictor_68_face_landmarks.dat')\n",
    "# shape_predictor = dlib.shape_predictor(data_dir + '/shape_predictor_5_face_landmarks.dat')\n",
    "face_recognition_model = dlib.face_recognition_model_v1(data_dir + '/dlib_face_recognition_resnet_model_v1.dat')\n",
    "\n",
    "\n",
    "def get_face_encodings(face):\n",
    "    bounds = face_detector(face, 1)\n",
    "    faces_landmarks = [shape_predictor(face, face_bounds) for face_bounds in bounds]\n",
    "    return [np.array(face_recognition_model.compute_face_descriptor(face, face_pose, 1)) for face_pose in faces_landmarks]\n",
    "\n",
    "\n",
    "def get_face_matches(known_faces, face):\n",
    "    return np.linalg.norm(known_faces - face, axis=1)\n",
    "\n",
    "\n",
    "def find_match(known_faces, person_names, face):\n",
    "    matches = get_face_matches(known_faces, face) # get a list of True/False\n",
    "    min_index = matches.argmin()\n",
    "    min_value = matches[min_index]\n",
    "    if min_value < 0.50:\n",
    "        return person_names[min_index]+\"! ({0:.2f})\".format(min_value)\n",
    "    if min_value < 0.55:\n",
    "        return person_names[min_index]+\" ({0:.2f})\".format(min_value)\n",
    "    if min_value < 0.60:\n",
    "        return person_names[min_index]+\"?\"+\" ({0:.2f})\".format(min_value)\n",
    "    return 'Not Found'\n",
    "\n",
    "\n",
    "def load_face_encodings(faces_folder_path):\n",
    "    image_filenames = filter(lambda x: x.endswith('.jpg'), os.listdir(faces_folder_path))\n",
    "    image_filenames = sorted(image_filenames)\n",
    "    person_names = [x[:-4] for x in image_filenames]\n",
    "\n",
    "    full_paths_to_images = [faces_folder_path + x for x in image_filenames]\n",
    "    face_encodings = []\n",
    "\n",
    "    win = dlib.image_window()\n",
    "\n",
    "    for path_to_image in full_paths_to_images:\n",
    "        face = io.imread(path_to_image)\n",
    "\n",
    "        faces_bounds = face_detector(face, 1)\n",
    "\n",
    "#         if len(faces_bounds) != 1:\n",
    "#             print(\"Expected one and only one face per image: \" + path_to_image + \" - it has \" + str(len(faces_bounds)))\n",
    "#             exit()\n",
    "        try:\n",
    "            face_bounds = faces_bounds[0]\n",
    "        except IndexError:\n",
    "            pass\n",
    "        face_landmarks = shape_predictor(face, face_bounds)\n",
    "        \n",
    "        face_encoding = np.array(face_recognition_model.compute_face_descriptor(face, face_landmarks, 1))\n",
    "\n",
    "        win.clear_overlay()\n",
    "        win.set_image(face)\n",
    "        win.add_overlay(face_bounds)\n",
    "        win.add_overlay(face_landmarks)\n",
    "        face_encodings.append(face_encoding)\n",
    "\n",
    "#         print(face_encoding)\n",
    "\n",
    "        #dlib.hit_enter_to_continue()\n",
    "    return face_encodings, person_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_faces_in_video(face_encodings, person_names):\n",
    "    \n",
    "    face_cascade = cv2.CascadeClassifier(data_dir + '/haarcascade_frontalface_default.xml')\n",
    "#     face_cascade = cv2.CascadeClassifier('/home/ml/Desktop/opencv-master/data/haarcascades_cuda/haarcascade_frontalface_default.xml')\n",
    "    unknown_counter = 0\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    for image in os.listdir(\"/home/john/dlib_files/frames\"):\n",
    "        image_path = os.path.join(\"/home/john/dlib_files/frames\",image)\n",
    "        image_name = image_path.split('/')[-1].strip('.jpg')\n",
    "        frame = cv2.imread(image_path)\n",
    "#         img = frame\n",
    "        height, width, channels = frame.shape\n",
    "        \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "        # Loop through all the faces detected \n",
    "        face_encodings_in_image = []\n",
    "        for (x, y, w, h) in faces:\n",
    "            x1 = x\n",
    "            y1 = y\n",
    "            x2 = x+w\n",
    "            y2 = y+h\n",
    "#             cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "            face = frame[max(0, y1):min(height, y2), max(0, x1):min(width, x2)] \n",
    "            face_encodings_in_image = get_face_encodings(face)\n",
    "            if len(face_encodings_in_image) >0:\n",
    "                img = cv2.rectangle(frame,(x1, y1),(x2, y2),(0,255,0),2)\n",
    "                match = find_match(face_encodings, person_names, face_encodings_in_image[0])\n",
    "                cv2.putText(frame, str(match), (x+5, y-15), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "                name = \"/home/john/dlib_files/labeled_frames/\"+ str(image_name) + '.jpg'\n",
    "            else:\n",
    "                cv2.rectangle(frame,(x1, y1),(x2, y2), (0, 0, 255), 2)\n",
    "                name = \"/home/john/dlib_files/labeled_frames/\"+ str(image_name) + '.jpg'\n",
    "                cv2.imwrite(name, frame)\n",
    "        name = \"/home/john/dlib_files/labeled_frames/\"+ str(image_name) + '.jpg'\n",
    "        cv2.imwrite(name, frame)\n",
    "        key = cv2.waitKey(100)\n",
    "#         cv2.imshow(\"Face Recognizer\", frame)\n",
    "\n",
    "        if key == 27: # exit on ESC\n",
    "            break\n",
    "#     vc.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.perf_counter()\n",
    "\n",
    "face_encodings, person_names = load_face_encodings(faces_folder_path)\n",
    "recognize_faces_in_video(face_encodings, person_names)\n",
    "\n",
    "t2 = time.perf_counter()\n",
    "print(f'Finished in {t2-t1} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get informations from images\n",
      "Transform frames to video\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# transform frames to video\n",
    "print(\"Transform frames to video\")\n",
    "video_transf.frame_to_video(DIR_FRAMES_AN, PATH_VID_AN,VID_FPS)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
